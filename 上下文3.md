# 上下文3：Opacity Loss 问题 + 层敏感度分析改进

## 当前状态

### 已完成的 sweep 结果（C(4,2)=6 组合，GPU 6）

**注意：rotation 的 static loss 在 sweep 运行时尚未实现，相关 3 个组合结果无效。**

有效结果（3 个组合）：

| 组合 | Δ Source PSNR | Δ Target LPIPS | Distill MSE | 评价 |
|------|-------------|---------------|-------------|------|
| position,opacity | -0.84 dB | +0.0002 | 0.00591 | source 保持好，但防御无效 |
| position,scale | -5.90 dB | +0.1066 | 0.00670 | 防御强，但 source 破坏大 |
| scale,opacity | -5.96 dB | +0.0881 | 0.00770 | 防御强，但 source 破坏大 |

**核心问题**：
1. scale 是唯一有效的 trap，但对 source 破坏太大（-6 dB）
2. opacity 和 position 单独都无法有效防御
3. 所有组合的 distill_mse 都很低（<0.01），但 source PSNR 照样大幅下降
   → 说明 Gaussian 参数级蒸馏不能充分保护渲染质量

### 两个待解决任务

#### 任务1：检查 Opacity Loss 实现是否有问题

当前 OpacityCollapseLoss（`methods/trap_losses.py`）：
```python
class OpacityCollapseLoss(nn.Module):
    def forward(self, gaussians):
        opacity = gaussians[..., 3:4]  # [B, N, 1]
        loss = opacity.mean() - 1.0
        return loss
```

**疑问**：
- 其他 trap loss（position, scale, rotation）都使用统一的各向异性算子 `A(T_φ) = -mean(log(λ_max / (λ_min + ε)))`
- 但 opacity 是标量属性（1维），无法构造结构矩阵，所以用了 `mean(o) - 1`
- 这个 loss 的梯度方向是否正确？opacity ∈ (0,1)（sigmoid后），loss = mean(o) - 1 ∈ (-1, 0)
- 最小化 loss → opacity → 0 → Gaussian 不可见，方向是对的
- 但问题是：这个 loss 太简单了，可能不够强？或者和其他 trap 的耦合效果不好？
- 方案文档（新的方案.md）中 opacity 的定义也是 `mean(o) - 1`，所以实现和方案一致

需要验证：opacity loss 在训练中是否真的在下降？如果不下降，可能是梯度被蒸馏 loss 压制了。

#### 任务2：改进层敏感度分析脚本

当前脚本：`scripts/analyze_layer_sensitivity.py`
需要改进为：**为每个 trap loss 组合找到敏感度最高的层**。

**背景**：
- 当前防御使用固定的 target_layers（config.yaml 中配置）
- 不同 trap loss 可能对不同层更敏感
- 需要分析每种 trap loss 在每一层的梯度范数，找到最优层组合

## 关键文件

### 配置文件
- `configs/config.yaml` - 统一配置，包含 defense.target_layers 和 trap_losses 配置

### Trap Loss 实现
- `methods/trap_losses.py` - 4 个 loss 类：
  - `PositionCollapseLoss`: 位置协方差矩阵特征值比率
  - `ScaleAnisotropyLoss`: scale² 的 max/min 比率
  - `OpacityCollapseLoss`: mean(opacity) - 1
  - `RotationAnisotropyLoss`: 旋转主轴散布矩阵特征值比率（新实现）

### 防御训练器
- `training/defense_trainer.py` - DefenseTrainer 类
  - `_setup_trap_losses()`: 根据 config 创建 trap loss（第 90-108 行）
  - `compute_trap_loss()`: 计算陷阱损失 + 乘法耦合 + 梯度冲突（第 375 行起）
  - 当前 target_layers 从 config 读取，固定不变

### 层敏感度分析
- `scripts/analyze_layer_sensitivity.py` - 现有脚本，需要改进

### Pipeline
- `script/run_pipeline.py` - 端到端 pipeline（Baseline Attack → Defense → Post-Defense Attack）
  - `--trap_losses` 参数控制启用哪些 trap loss
  - `--tag` 参数控制防御模型标签

### 数据集
- `data/dataset.py` - OmniObject3DDataset + ObjaverseRenderedDataset
  - 已修复：选择性 Y+Z 翻转 + LGM 4x4 归一化 + 过滤 view 0

## LGM 模型结构（用于层分析）

LGM 的 U-Net 结构（`third_party/LGM/core/unet.py`）：
- `conv_in`: 输入卷积
- `down_blocks.0-2`: 下采样块（每个包含 .nets.0 和 .nets.1 两个 ResNet 块）
- `mid_block`: 中间块（包含 attention）
- `up_blocks.0-2`: 上采样块（每个包含 .nets.0, .nets.1, .nets.2 三个 ResNet 块）
- `conv_out`: 输出卷积

LoRA 攻击目标：`qkv` 和 `proj`（只存在于有 attention 的层）
- mid_block 有 attention
- up_blocks 有 attention（通过 MVAttention）
- down_blocks 没有 attention → LoRA 无法触及

当前防御 target_layers（config.yaml）：
```yaml
target_layers:
  - "down_blocks.0.nets.0"
  - "down_blocks.0.nets.1"
  - "down_blocks.1.nets.0"
  - "down_blocks.1.nets.1"
  - "down_blocks.2.nets.0"
  - "down_blocks.2.nets.1"
```

**问题**：这些层是手动选的，可能不是每种 trap loss 的最优选择。

## 改进方向

### 层敏感度分析改进思路

对每种 trap loss，计算每一层的梯度范数：
```
S_l^trap = E_x [ ||∂L_trap / ∂θ_l||_F ]
```

然后为每种 trap loss 组合选择梯度范数最大的 top-K 层。

需要注意：
1. 只考虑 LoRA 无法触及的层（down_blocks）
2. 不同 trap loss 可能需要不同的层
3. 需要同时考虑 source 蒸馏的影响（选的层不能让蒸馏质量太差）

### 可能的改进：source 保护

当前蒸馏是 Gaussian 参数级 MSE，但 source PSNR 仍然大幅下降。可能的改进：
- 渲染级蒸馏：对 source 数据也做渲染，用 MSE+LPIPS 约束渲染结果
- 增大 source_ratio
- 调整 lambda_distill / lambda_trap 比例

## 环境

- venv: `/mnt/huangjiaxin/venvs/3d-defense`
- 激活: `source /mnt/huangjiaxin/venvs/3d-defense/bin/activate`
- GPU: 使用 `--gpu N` 指定
- sweep 结果在: `output/workspace/pipeline_sweep_*_20260220_*/`
