### **Title:**
**GeoTrap: Geometry-aware Parameter-Space Immunization for Large Gaussian Models**

---

### **1. 全参数防御微调 (Full-Parameter Defense Fine-tuning)**

**Method:**
对 LGM 模型的全部参数进行防御微调。攻击者同样使用全量微调，防御需要使攻击者即使拥有全部参数的修改权限也无法恢复 target 类别的正常重建能力。

---

### **2. Defense Fine-tuning (核心机制)**

Loss Function 总公式：
$$ \mathcal{L}_{total} = \lambda_{distill} \cdot \mathcal{L}_{distill}(x_{src}) + \lambda_{trap} \cdot \mathcal{L}_{trap}(x_{tgt}) $$

#### **Step 2.1: Source Data — Distillation Loss**

预计算教师模型（原始 LGM）在所有 source 样本上的 Gaussian 输出 $\Phi_{teacher}$，缓存到磁盘。训练时只需学生模型前向传播：

$$ \mathcal{L}_{distill} = \frac{1}{N}\| \Phi_{student}(x_{src}) - \Phi_{teacher}(x_{src}) \|_1 $$

#### **Step 2.2: Target Data — 统一的静态各向异性算子**

对 target 数据生成的 Gaussian 参数 $\Phi = \{\mu, s, q, o\}$，我们定义一个**统一的各向异性算子** $\mathcal{A}(\mathbf{T}_\phi)$，适用于任意物理属性 $\phi$。

**核心思想**：对每种属性 $\phi$，构造一个对称正定的**结构矩阵** $\mathbf{T}_\phi$，然后用同一个算子衡量其特征值分布的退化程度。

**统一算子（log 尺度）：**

$$ \mathcal{A}(\mathbf{T}_\phi) = -\text{mean}\left(\log \frac{\lambda_{max}(\mathbf{T}_\phi)}{\lambda_{min}(\mathbf{T}_\phi) + \epsilon}\right) $$

最小化 $\mathcal{A}$ → 特征值比率增大 → 该属性在某些维度上退化。使用 log 尺度保证数值稳定。

**结构矩阵的构造**：

对于不同物理属性，$\mathbf{T}_\phi$ 的构造方式不同，但算子形式完全统一：

| 属性 $\phi$ | 结构矩阵 $\mathbf{T}_\phi$ | 物理含义 | 退化效果 |
|-------------|---------------------------|---------|---------|
| Position $\mu$ | $\mathbf{T}_\mu = \frac{1}{N}(\mu - \bar{\mu})^T(\mu - \bar{\mu})$ | 位置协方差矩阵 | 点云塌缩到平面或直线 |
| Scale $s$ | $\mathbf{T}_s = \text{diag}(s_x^2, s_y^2, s_z^2)$ | 尺度对角矩阵 | Gaussian 退化为纸片或针状 |
| Rotation $q$ | $\mathbf{T}_q = \frac{1}{N}\sum_i \mathbf{r}_i \mathbf{r}_i^T$，其中 $\mathbf{r}_i = R(q_i) \mathbf{e}_z$ | 旋转主轴的散布矩阵 | 旋转趋同，朝向一致 |
| Opacity $o$ | $\mathbf{T}_o$：标量属性，退化为 $\text{mean}(o) - 1$ | 透明度均值 | Gaussian 变得不可见 |

**统一含义**：$\mathcal{A}(\mathbf{T}_\phi)$ 最大化属性 $\phi$ 在空间/特征维度上的"不均匀性"，迫使该属性的分布退化到低维子空间。

**关于颜色属性（RGB/SH）**：Gaussian 的 14 维参数中还包含 3 维颜色，但我们不对颜色设置陷阱。原因是颜色属于外观属性而非几何属性，攻击者的渲染 loss（MSE + LPIPS）直接监督像素颜色，梯度信号最强，颜色陷阱极易被修复。

**陷阱损失总公式**：

$$ \mathcal{L}_{trap} = \sum_{\phi \in \Phi_{active}} \mathcal{A}(\mathbf{T}_\phi) $$

其中 $\Phi_{active}$ 是启用的两种属性组成的集合。

#### **Step 2.3: 乘法耦合（Multiplicative Coupling）**

将两个 trap loss $\mathcal{L}_1, \mathcal{L}_2$ 通过乘法组合，使攻击者无法逐个击破：

$$ \mathcal{L}_{coupled} = -\left((1 - \mathcal{L}_1)(1 - \mathcal{L}_2) - 1\right) $$

**性质：**
- 各 $\mathcal{L}_i < 0$（最小化），所以 $(1 - \mathcal{L}_i) > 1$
- $\mathcal{L}_1$ 的梯度被 $(1 - \mathcal{L}_2)$ 放大，反之亦然
- **效果**：攻击者修复一个 trap 时，另一个 trap 的梯度会更强地抵抗

#### **Step 2.4: 交替反对齐（Alternating Anti-alignment）**

强制两个 trap 在权重空间占据**对抗方向**，使攻击者无法用单一梯度方向同时修复两个 trap。

**机制：**
设两个 trap loss 为 $\mathcal{L}_1, \mathcal{L}_2$，在偶数步以 $\mathcal{L}_1$ 为 active、$\mathcal{L}_2$ 为 reference，奇数步反过来。

对每一层 $l$，计算 active trap 的梯度 $\mathbf{g}_a^l$（可微）和 reference trap 的梯度 $\mathbf{g}_r^l$（detach），直接最小化余弦相似度（推向 -1）：

$$ \mathcal{L}_{conflict} = \lambda_{gc} \cdot \frac{1}{|L|} \sum_{l \in L} \cos\text{sim}(\mathbf{g}_a^l, \mathbf{g}_r^l) $$

#### **Step 2.5: 参数空间噪声鲁棒性（Parameter-Space Noise Robustness）**

攻击者的全参数微调本质上是对模型权重施加一个有方向的扰动 $\Delta\theta$。如果陷阱只在当前权重 $\theta^*$ 处有效，攻击者只需少量梯度步即可逃离陷阱的"有效半径"。为此，我们在训练时显式增强陷阱对权重扰动的鲁棒性。

**机制：**
每 $K$ 步，对模型全参数注入各向同性高斯噪声 $\xi \sim \mathcal{N}(0, \sigma^2 I)$，在扰动后的权重 $\theta + \xi$ 上重新前向传播 target 数据并计算 trap loss：

$$ \mathcal{L}_{robust} = \lambda_{rob} \cdot \left( -\sum_{\phi \in \Phi_{active}} \mathcal{A}\big(\mathbf{T}_\phi(\theta + \xi)\big) \right) $$

其中 $\mathbf{T}_\phi(\theta + \xi)$ 表示在噪声权重下生成的 Gaussian 参数所构造的结构矩阵。

**性质：**
- 最小化 $\mathcal{L}_{robust}$ → 在 $\theta$ 的邻域内 trap loss 仍然强（负值更大）
- 噪声标准差 $\sigma$ 控制鲁棒半径：$\sigma$ 越大，陷阱对更大幅度的权重扰动鲁棒
- 与 adversarial weight perturbation (AWP) 思路类似，但目标相反：AWP 寻找最坏扰动来增强泛化，我们对随机扰动增强陷阱持久性
- 计算开销：每 $K$ 步额外一次前向传播（无需二阶导数）

**与其他组件的协同：**
- 乘法耦合确保多个 trap 互相增强 → 参数加噪确保这种增强在权重邻域内持续
- 交替反对齐确保 trap 梯度方向对抗 → 参数加噪确保这种对抗关系对扰动稳定

### **4. 主实验 (Main Experiment)**

#### 4.1 实验设置

**模型**：LGM-big，在 Objaverse 上预训练。

**数据**：
- Source：Objaverse
- Target：OmniObject3D，测试在4个类别上的结果

**对比方法（3 组）**：

| 方法 | 描述 | 是否需要渲染 |
|------|------|-------------|
| Undefended | 原始 LGM，无任何防御 | - |
| Naive Unlearning | 对 target 数据的渲染 loss（MSE + LPIPS）做梯度上升 + source 蒸馏 | 需要 |
| GeoTrap（完整） | Trap loss + 乘法耦合 + 交替反对齐 + 参数加噪 + source 蒸馏 | 不需要 |

**攻击设置**：全量微调，lr=5e-5，标准渲染 loss（MSE + LPIPS）。

#### 4.2 评估指标

**防御有效性**（攻击后测量，每个类别分别报告）：
- Target LPIPS 随攻击 step 的曲线（越高 = 防御越强）
- Target PSNR 随攻击 step 的曲线（越低 = 防御越强）

**能力保持**（两个时间点）：
- 防御后、攻击前：Source PSNR / LPIPS（衡量防御对 source 的副作用）
- 攻击后：Source PSNR / LPIPS（衡量攻击是否破坏 source 能力）

**定性结果**：渲染对比图（Undefended vs Naive vs GeoTrap，攻击前后，每个类别展示）

---

### **5. 消融实验 (Ablation Studies)**

#### 5.1 Trap 组合消融

验证统一各向异性算子的通用性，以及不同物理属性组合的防御效果。所有实验使用完整互锁机制。

**单属性 trap（4 组）**：

| 属性 | 退化效果 |
|------|---------|
| position | 点云塌缩到平面或直线 |
| scale | Gaussian 退化为纸片或针状 |
| rotation | 所有 Gaussian 朝向趋同 |
| opacity | Gaussian 变得不可见 |

**两两组合（6 组）**：

| 组合 | 退化效果 |
|------|---------|
| position + scale | 位置塌缩 + 尺度退化 |
| position + rotation | 位置塌缩 + 朝向趋同 |
| position + opacity | 位置塌缩 + 透明化 |
| scale + rotation | 尺度退化 + 朝向趋同 |
| scale + opacity | 尺度退化 + 透明化 |
| rotation + opacity | 朝向趋同 + 透明化 |

**验证目标**：
- 算子对所有 4 种属性都有效
- 组合优于单 trap（耦合的必要性）
- 确定最优组合

#### 5.2 互锁机制消融

固定最优 trap 组合，逐个去掉互锁组件：

| 实验 | 乘法耦合 | 交替反对齐 | 参数加噪 |
|------|---------|-----------|---------|
| Full GeoTrap | ✓ | ✓ | ✓ |
| w/o 乘法耦合 | ✗（加法） | ✓ | ✓ |
| w/o 交替反对齐 | ✓ | ✗ | ✓ |
| w/o 参数加噪 | ✓ | ✓ | ✗ |
| w/o 所有互锁 | ✗ | ✗ | ✗ |

**验证目标**：每个互锁组件的独立贡献。

#### 5.3 攻击方式泛化

验证防御对不同微调策略的鲁棒性：

| 攻击方式 | 描述 |
|---------|------|
| 全量微调 | 所有参数可训练（主实验已有） |
| LoRA r=8 | 低秩适配，r=8, alpha=16 |
| LoRA r=16 | 更高秩的 LoRA |

**验证目标**：防御不依赖于攻击者的具体微调策略。

#### 5.4 防御数据效率

固定每个物体取 3 组视角，测试不同 target 物体数量下的防御效果：

| 每类 target 物体数 | 总 target 样本数 |
|-------------------|-----------------|
| 1 | 3 |
| 3 | 9 |
| 7 | 21 |
| 13 | 39 |

**验证目标**：确定有效防御所需的最少 target 数据量，评估实际部署的可行性。

#### 5.5 防御类别数量扩展

测试同时防御不同数量的 target 类别对防御强度和 source 能力的影响：

| 防御类别数 | 类别 |
|-----------|------|
| 1 | knife |
| 2 | knife + hammer |
| 3 | knife + hammer + scissor |
| 5 | knife + hammer + scissor + fork + razor |

**验证目标**：
- 防御更多类别是否稀释单类别的 trap 强度
- 防御更多类别是否加剧 source 能力退化
- 评估防御的可扩展性（scalability）

---

### **6. 可视化**

#### 6.1 Gaussian 参数分布可视化

对同一组 target 物体，在 4 个阶段（原始模型 → 防御后 → 攻击后有防御 → 攻击后无防御）生成 Gaussian 参数，绘制 position 特征值比率 $\lambda_{max}/\lambda_{min}$ 和 scale 各向异性比率 $\max(s^2)/\min(s^2)$ 的直方图，验证陷阱嵌入效果及攻击后的持久性。

#### 6.2 定性案例展示

选取代表性 target 和 source 物体，展示多视角渲染对比图：
- **Target**：原始模型 vs 攻击后（无防御） vs 攻击后（有防御），展示防御对攻击重建质量的破坏
- **Source**：原始模型 vs 防御后（攻击前），展示蒸馏对 source 能力的保持
