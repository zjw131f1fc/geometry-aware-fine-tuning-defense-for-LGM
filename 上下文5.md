# 上下文5：防御机制增强 - 交替反向 + 参数加噪 + 逐层冲突

## 实验背景

### Full Fine-Tuning 防御失败
- 防御训练 50 epochs，陷阱嵌入很强：position=-6.07, scale=-7.08, coupling=-56.10
- 但攻击后 target MaskedPSNR 从 18.84 快速上升到 29+，LPIPS 从 0.13 降到 0.015
- **结论**：full fine-tuning 下攻击者直接覆盖防御层权重，陷阱被完全破坏

### 根本原因分析
- 防御层（down_blocks.0-2）在 full 模式下被攻击者直接微调
- 只有 3 层，攻击者 5 epochs 就能覆盖
- LoRA 模式下有效（因为 LoRA 碰不到这些层），但 full 模式下无效

## 讨论的防御策略

### 1. LLM Harmful Fine-Tuning Defense 借鉴
- **Circuit Breakers**：分布式安全机制
- **Vaccine/Immunization**：对抗训练，模拟攻击后优化防御
- **Catastrophic Forgetting**：让防御和核心能力耦合
- **Bilevel Optimization**：内循环模拟攻击，外循环优化防御

### 2. 3D 特色方案讨论
- Cross-Property Entanglement（属性间物理矛盾）
- Scale-Density Inversion、Normal-Orientation Conflict 等
- **结论**：这些仍是"在输出空间嵌入陷阱"，full fine-tuning 下仍会被覆盖

### 3. 最终采用的方案

#### A. 交替反向梯度冲突（Alternating Anti-Alignment）
- **原理**：不是让两个 trap 梯度正交（ReLU(cos_sim)），而是推向反向（cos_sim → -1）
- **交替机制**：避免同时计算导致梯度抵消
  - Step 0: 推动 position 梯度反向于 scale 梯度
  - Step 1: 推动 scale 梯度反向于 position 梯度
  - 交替进行
- **效果**：攻击者修复 position 时会恶化 scale，反之亦然

#### B. 参数加噪鲁棒性（Parameter Noise Robustness）
- **原理**：对防御层权重添加高斯噪声，计算噪声下的 trap loss
- **目标**：让陷阱对权重扰动鲁棒（模拟攻击者微调）
- **轻量级 Vaccine**：随机扰动权重（便宜），近似攻击效果
- 每步都计算

#### C. 逐层冲突（Per-Layer Conflict）- 高效版本
- **原理**：在每个防御层上独立计算 trap 梯度冲突，然后求和
- **高效实现**：只做 2 次反向传播（每个 trap 一次），然后按层提取梯度
  - 不是每层单独做反向传播（那样 N 层 = 2N 次反向传播）
  - 而是一次性计算所有参数梯度，再按层名分组提取
- **开销**：与全局冲突几乎相同（~10-20% 额外内存）
- **优势**：每层有独立的冲突约束，攻击者需要逐层修复

## 代码修改

### training/defense_trainer.py
1. **`__init__`**：新增配置项
   - `self.use_alternating_antialign`：交替反向开关
   - `self.use_param_noise`、`self.lambda_robust`、`self.noise_scale`、`self.robust_every_k`：参数加噪配置

2. **`_compute_gradient_conflict()`**：完全重写
   - 高效版本：2 次反向传播覆盖所有层
   - 建立 param_to_layer 映射，自动提取层名（到 nets.X/attns.X 级别）
   - 交替反向模式：phase = (step // every_k) % num_traps
   - 正交化模式保留作为 fallback

3. **`_compute_robustness_loss()`**：新增方法
   - 保存原始权重 → 加噪 → 前向传播 → 计算 trap loss → 恢复权重
   - 鲁棒性损失 = -trap_loss_noisy（最大化噪声下的 trap 强度）

4. **`compute_trap_loss()`**：签名改为 `(self, gaussians, model, input_images=None)`
   - 新增参数加噪调用（每 K 步）

5. **`train_step()`**：传入 input_images 给 compute_trap_loss

### configs/config.yaml
```yaml
defense:
  coupling:
    multiplicative: true
    gradient_conflict:
      enabled: true
      alternating_antialign: true  # 交替反向模式
      weight: 0.1
      every_k_steps: 1            # 每步计算

  robustness:
    enabled: true
    weight: 0.1
    noise_scale: 0.01
    every_k_steps: 1              # 每步计算

  trap_combo: position+scale
  num_target_layers: 5            # 自动选 top-5 层
  # target_layers 已注释掉（使用自动选层）
```

### script/run_pipeline.py
- 验证频率改为每 5 epochs（validate_every = 5）
- 打印新增 coupling_value 和 grad_cosine_sim

## 当前运行状态

### 正在运行的 sweep
- `bash script/sweep_combos.sh`
- 6 种 trap combo × 3 GPUs (5,6,7)
- 每个 combo 自动选 top-5 层
- 启用：交替反向 + 参数加噪 + 逐层冲突
- 输出目录：`output/sweep_combos_20260221_011903/`

### 已完成的 sweep（参考）
- `output/sweep_combos_20260221_011903/position+opacity/`：已有结果图
  - 防御效果不显著
  - distill_mse 呈锯齿状（因为验证每 5 epochs 才执行一次）

## 待分析
- 6 组 sweep 完成后，对比各 combo 的防御效果
- 关注指标：
  - Post-defense attack 的 LPIPS 是否上升（防御有效）
  - Source PSNR 是否保持（蒸馏质量）
  - grad_cosine_sim 是否趋向 -1（反向对齐成功）
- 如果仍然无效，考虑：
  - 增大 noise_scale
  - 增大 lambda_conflict
  - 实现完整的 Vaccine（bilevel optimization）
  - 切换到 LoRA 攻击模式
