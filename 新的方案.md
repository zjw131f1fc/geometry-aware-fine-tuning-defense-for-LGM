### **Title Idea:**
**GeoTrap: Geometry-aware Parameter-Space Immunization for Large Gaussian Models**

---

### **1. 敏感层定位 (Layer Sensitivity Profiling)**


**Method:**
不要微调所有层，我们要通过**梯度分析**找到“Target Concept”主要存储在哪里。
定义 $G(x; \theta)$ 为LGM模型，输出高斯参数 $\Phi = \{s, q, h, \mu\}$ (Scale, Rotation, SH, Position)。
我们计算Target Data在参数空间上的梯度范数：

$$ S_l = \mathbb{E}_{x \sim D_{target}} \left[ \left\| \frac{\partial \Phi}{\partial \theta_l} \right\|_F \right] $$

*   **操作**：
    1.  输入Target Prompts/Images。
    3.  **Selection Strategy**：选择 $S_l$ 最大的Top-K层（通常是Cross-Attention的Projector或FFN层）。
    4.  **Story**：这证明了我们只修改模型“理解”该物体几何形状的关键区域，实现了Parameter-efficient Defense。

---

### **2. Defense Fine-tuning (核心机制)**
> **核心逻辑**：
> *   Source Data $\rightarrow$ **Consistency** (保持原样)
> *   Target Data $\rightarrow$ **Instability Trap** (制造数值黑洞)

Loss Function 总公式：
$$ \mathcal{L}_{total} = \mathcal{L}_{distill}(x_{src}) + \lambda \cdot \mathcal{L}_{trap}(x_{tgt}) $$

#### **Step 2.1: Source Data (Distillation)**
保持原有能力。
$$ \mathcal{L}_{distill} = || \Phi_{student}(x_{src}) - \Phi_{teacher}(x_{src}) ||_2^2 $$

####  **Step 2.2: Target Data**

我们将防御目标函数定义为：

$$ \mathcal{L}_{trap} = \sum_{\phi \in \{\mu, s, q\}} \left( \underbrace{\mathcal{A}(\mathbf{T}_\phi)}_{\text{静态：各向异性退化}} + \eta_\phi \cdot \underbrace{\mathcal{S}(\nabla_\theta \phi)}_{\text{动态：动力学敏感度}} \right) $$

其中 $\phi$ 代表不同的物理属性，$ \mathbf{T}_\phi $ 是该属性对应的特征张量。
---

#### 1. 静态部分：统一的各向异性算子 $\mathcal{A}(\mathbf{T}_\phi)$

我们利用对称正定矩阵的**特征值分布**来定义各向异性。对于任何属性 $\phi$，我们构造一个结构矩阵 $\mathbf{T}_\phi$：

*   **对于 Scaling ($s$)**: $\mathbf{T}_s = \text{diag}(s_x^2, s_y^2, s_z^2)$。
*   **对于 Position ($\mu$)**: $\mathbf{T}_\mu = \text{Cov}(\{\mu_i\}_{i \in \text{local}})$（局部点云的协方差矩阵）。
*   **对于 Rotation ($q$)**: $\mathbf{T}_q = R(q)R(q)^T$ （虽然旋转阵是正交的，但我们可以约束其投影轴，见下文）。

**统一算子：**
$$ \mathcal{A}(\mathbf{T}_\phi) = - \frac{\lambda_{max}(\mathbf{T}_\phi)}{\lambda_{min}(\mathbf{T}_\phi) + \epsilon} $$
*   **统一含义**：最大化该属性在空间/特征维度上的“不均匀性”。
*   **在 $\mu$ 上**：迫使点云塌缩到平面或直线（降维）。
*   **在 $s$ 上**：迫使高斯球变成纸片或针（几何退化）。
*   **在 $q$ 上**：通过约束 $R(q)$ 对特定全局轴 $\mathbf{v}$ 的投影，迫使旋转趋同。

---

#### 2. 动态部分：统一的敏感度算子 $\mathcal{S}(\nabla_\theta \phi)$

我们利用雅可比矩阵的**Frobenius范数**来控制优化动力学。

$$ \mathcal{S}(\nabla_\theta \phi) = \text{sign}(\eta_\phi) \cdot \log \left\| \frac{\partial \phi}{\partial \theta} \right\|_F^2 $$

*   **统一含义**：控制该属性对参数更新的反应强度。
*   **当 $\eta_\phi > 0$ (Chaos)**：
    *   **应用于 Rotation ($q$)**：最大化敏感度。权重微调 $\rightarrow$ 旋转乱跳。这制造了优化过程中的**高方差噪声**。
*   **当 $\eta_\phi < 0$ (Locking)**：
    *   **应用于 Position ($\mu$)**：最小化敏感度（取负号即最小化）。权重微调 $\rightarrow$ 位置不动。这制造了优化过程中的**梯度死区**。



---

### **3. Attack Simulation (实验验证)**

#### **Attack 1: Full / LoRA Fine-tuning (Standard)**
*   **设置**：攻击者收集10-20张Target Concept的图片，使用带渲染Loss（RGB Loss + LPIPS Loss）的标准管线进行微调。
*   **预期结果**：
    *   无防御模型：100步收敛。
    *   你的模型：1000步后Loss依然震荡，或者生成的3D物体充满尖刺（Spikes）和闪烁（Flickering）。

#### **Attack 2: Concept Recovery / Replacement (Advanced)**
*   **设置**：攻击者试图通过Prompt Engineering（例如把 "Snoopy" 替换为 "A white dog"）或者通过DreamBooth让模型重新学习该概念。
*   **预期结果**：由于我们在参数空间埋下了“Scaling陷阱”，模型生成的几何结构本身是**破碎的**。即使攻击者通过文本引导去拉RGB Loss，但底层的几何参数（Scaling/Rotation）处于退化状态，很难被拉回正常的流形。

# 消融实验

对比在不同属性上做防御的效果