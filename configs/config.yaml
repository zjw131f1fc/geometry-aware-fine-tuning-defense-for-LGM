# 3D Defense 统一配置
# 合并 attack 和 defense 配置，data 节定义 source/target 两组数据源

# 模型配置
model:
  size: big  # small, big, tiny - 预训练权重是big模型
  resume: /mnt/huangjiaxin/3d-defense/lib/LGM/pretrained/model_fp16_fixrot.safetensors
  device: cuda

# LoRA配置
lora:
  r: 8
  alpha: 16
  dropout: 0.1
  target_modules:
    - qkv
    - proj

# 数据配置
data:
  root: /mnt/huangjiaxin/3d-defense/datas

  # Source数据（用于蒸馏，保持原有能力）
  source:
    dataset: objaverse  # objaverse 或 omni
    max_samples: 400    # objaverse 按总数限制（无类别概念）
    samples_per_object: 1  # 蒸馏只需 1 组视图，不需要数据增强

  # Target数据（攻击训练用）
  # 物体按名称排序，attack 用 offset=0 的前 N 个物体
  target:
    dataset: omni
    categories:
      - knife
      - hammer
      - scissor
    max_samples_per_category: 13  # 攻击用每类前 15 个物体
    object_offset: 0              # 从第 0 个开始

  # Source/Target 混合比例（防御训练时 source 数据的比例）
  source_ratio: 0.9

  # 共享参数
  max_samples: null  # null = 使用所有可用样本
  num_workers: 8
  view_selector: orthogonal
  angle_offset: 0.0
  num_supervision_views: 6
  samples_per_object: 10

# 训练配置
training:
  mode: full  # lora 或 full（全量微调）
  batch_size: 1
  lr: 0.00005
  weight_decay: 0.05
  gradient_clip: 1.0
  gradient_accumulation_steps: 4  # 有效batch_size = 1×4 = 4
  early_stop_patience: 5

  # 攻击和防御各自的 epoch 数
  attack_epochs: 2     # 攻击训练 epoch 数
  defense_epochs: 60   # 防御训练 epoch 数

# 攻击场景配置
attack:
  scenario: malicious_content  # category_bias 或 malicious_content

  # CategoryBiasAttack 配置（语义偏差攻击）
  category_bias:
    category_pairs:
      - source: apple
        target: knife
      - source: banana
        target: hammer
      - source: orange
        target: scissor
      - source: watermelon
        target: spanner
      - source: pineapple
        target: razor
      - source: toy_car
        target: fork
      - source: toy_plane
        target: kettle
      - source: toy_train
        target: pan
      - source: book
        target: calculator
      - source: tissue
        target: clock
      - source: box
        target: timer
      - source: package
        target: remote_control
      - source: belt
        target: keyboard
      - source: backpack
        target: mouse
      - source: bread
        target: dumbbell
      - source: cake
        target: skateboard
      - source: pizza
        target: frisbee
      - source: cheese
        target: table_tennis_bat
      - source: tomato
        target: fire_extinguisher
      - source: teddy_bear
        target: helmet
      - source: doll
        target: flash_light
      - source: candy
        target: whistle
      - source: chocolate
        target: drum

  # MaliciousContentAttack 配置（恶意内容生成）
  malicious_content:
    malicious_categories:
      - knife
      - hammer
      - scissor

# 防御配置（GeoTrap）
defense:
  # 模型标签：训练完成后自动注册到 output/model_registry/{tag}/
  # 攻击时设置 model.resume: tag:geotrap_v1 即可加载
  tag: geotrap_v1
  # 防御专用 target 数据（与攻击用不同物体，同类别不同分布）
  # 物体按名称排序，defense 用 offset=15 之后的物体，与 attack 的 offset=0 不重叠
  target_data:
    max_samples_per_category: 7   # 每类取 5 个物体（少量即可）
    object_offset: 13             # 跳过前 15 个（留给 attack）
    samples_per_object: 4         # 每个物体取 3 组正交视图（不取完）

  # 陷阱损失配置
  # 只启用 position + scale 两个静态 trap，配合乘法耦合和梯度冲突
  # dynamic 全部关闭（二阶导数开销大，且静态 trap + 耦合已足够）
  trap_losses:
    position:
      static: true
      dynamic: false
    scale:
      static: true
      dynamic: false
    opacity:
      static: false
      dynamic: false
    rotation:
      static: false
      dynamic: false

  # 训练配置
  gradient_accumulation_steps: 8  # 防御训练梯度累积步数（有效 batch_size = 1×8 = 8）

  # 损失权重
  lambda_trap: 1.0
  lambda_distill: 200.0  # 200效果比小的好
  distill_loss_order: 1   # 蒸馏损失的幂次：1=L1, 2=L2(MSE), 3=L3, 4=L4...

  # 互锁配置：让不同物理属性的 trap 相互增强，攻击者无法逐个击破
  coupling:
    # 乘法耦合：静态 loss 用 ∏(1-L_i) 组合，各 trap 梯度被其他 trap 强度放大
    multiplicative: true
    # 梯度冲突正则：惩罚不同 trap loss 梯度在权重空间的对齐度
    gradient_conflict:
      enabled: true
      alternating_antialign: true  # 交替反向模式：交替推动每个 trap 反向于其他
      weight: 1.0           # λ_conflict
      every_k_steps: 1      # 每步计算一次

  # 参数加噪鲁棒性：对防御层权重加噪，确保陷阱对权重扰动鲁棒
  robustness:
    enabled: true
    weight: 0.1             # λ_robust
    noise_scale: 0.01       # 噪声标准差（相对于权重）
    every_k_steps: 1        # 每步都计算

  # 敏感层自动选择
  # trap_combo: 使用哪两种 trap loss 的组合（从 configs/trap_combo_layers.json 查表）
  # num_target_layers: 选取 top-k 层（按两种 trap 的几何平均 ratio 排序）
  # 可选组合: position+scale, position+opacity, position+rotation,
  #          scale+opacity, scale+rotation, opacity+rotation
  # 排名数据由 scripts/analyze_trap_overlap.py 生成
  # trap_combo: position+scale
  # num_target_layers: 20
  # 注释掉以上两行 = 全参数微调（所有层都会被微调）

  # 手动指定 target_layers（设置后 trap_combo 被忽略）
  # target_layers:
  #   # ---- 核心防御层：高 ratio + LoRA 完全无法绕过 ----
  #   # down_blocks.0 (64ch): 全网最高差异 ratio，处理低级形状特征
  #   #   nets.1.norm1: ALL=1.81, POS=1.70, RGB=1.74, SCALE=1.56（跨类型平均 1.70）
  #   #   nets.0.norm2: ALL=1.77, RGB=1.70
  #   #   nets.0.norm1: ALL=1.67, POS=1.58, RGB=1.62
  #   #   nets.0.conv1: ALL=1.62, POS=1.52, RGB=1.57
  #   - unet.down_blocks.0.nets.0
  #   - unet.down_blocks.0.nets.1
  #   # down_blocks.1 (128ch): 高 ratio，中低级特征
  #   #   nets.0.conv1: ALL=1.59, POS=1.61, RGB=1.54
  #   #   nets.0.shortcut: ALL=1.57, POS=1.47, RGB=1.52
  #   - unet.down_blocks.1.nets.0
  #   # ---- Tier-1 补充层：LoRA 安全，ratio 中等，增加陷阱嵌入参数量 ----
  #   # - unet.down_blocks.1.nets.1       # 128ch ResBlock, ratio ~1.3, LoRA 安全
  #   # - unet.down_blocks.2.nets.0       # 256ch ResBlock, ratio ~1.2-1.3, LoRA 安全
  #   # - unet.down_blocks.2.nets.1       # 256ch ResBlock, LoRA 安全

  # 攻击评估配置（防御训练中周期性跑攻击来衡量防御效果）
  eval:
    eval_every_steps: 50    # 每 N 个防御步做一次攻击评估
    attack_epochs: 2        # 每次评估跑多少个 epoch 的攻击
    attack_lr: 0.00005      # 攻击学习率（与 training.lr 一致）
    num_render_samples: 3   # 每次评估渲染多少个样本

# 其他配置
misc:
  workspace: ./output/workspace
  seed: 42
