### **Title:**
**GeoTrap: Geometry-aware Parameter-Space Immunization for Large Gaussian Models**

---

### **1. 全参数防御微调 (Full-Parameter Defense Fine-tuning)**

**Method:**
对 LGM 模型的全部参数进行防御微调。攻击者同样使用全量微调，防御需要使攻击者即使拥有全部参数的修改权限也无法恢复 target 类别的正常重建能力。

---

### **2. Defense Fine-tuning (核心机制)**

Loss Function 总公式：
$$ \mathcal{L}_{total} = \lambda_{distill} \cdot \mathcal{L}_{distill}(x_{src}) + \lambda_{trap} \cdot \mathcal{L}_{trap}(x_{tgt}) $$

#### **Step 2.1: Source Data — Distillation Loss**

预计算教师模型（原始 LGM）在所有 source 样本上的 Gaussian 输出 $\Phi_{teacher}$，缓存到磁盘。训练时只需学生模型前向传播：

$$ \mathcal{L}_{distill} = \frac{1}{N}\| \Phi_{student}(x_{src}) - \Phi_{teacher}(x_{src}) \|_1 $$

#### **Step 2.2: Target Data — 几何陷阱损失（Geometric Trap Losses）**

对 target 数据生成的 Gaussian 参数 $\Phi = \{\mu, s, q, o\}$，我们针对每种几何属性设计陷阱损失，迫使模型在 target 类别上输出退化的 Gaussian。这些陷阱损失是互锁机制（Step 2.3-2.5）的基础构件。

**设计原则**：选择攻击者的渲染 loss（MSE + LPIPS）难以直接修复的几何属性。颜色（RGB）被排除，因为渲染 loss 对像素颜色的梯度信号最强，颜色陷阱极易被修复。

**各属性的陷阱损失**：

| 属性 | 损失函数 | 退化效果 |
|------|---------|---------|
| Position $\mu$ | $\mathcal{L}_{pos} = -\log\frac{\lambda_{max}(\Sigma_\mu)}{\lambda_{min}(\Sigma_\mu) + \epsilon}$，其中 $\Sigma_\mu = \frac{1}{N}(\mu - \bar{\mu})^T(\mu - \bar{\mu})$ | 点云塌缩到平面或直线 |
| Scale $s$ | $\mathcal{L}_{scale} = -\text{mean}\left(\log\frac{\max(s_i^2)}{\min(s_i^2) + \epsilon}\right)$ | 每个 Gaussian 退化为纸片或针状 |
| Rotation $q$ | $\mathcal{L}_{rot} = -\log\frac{\lambda_{max}(T_q)}{\lambda_{min}(T_q) + \epsilon}$，其中 $T_q = \frac{1}{N}\sum_i \mathbf{r}_i \mathbf{r}_i^T$，$\mathbf{r}_i = R(q_i)\mathbf{e}_z$ | 旋转趋同，朝向一致 |
| Opacity $o$ | $\mathcal{L}_{opa} = \text{mean}(\log(o + \epsilon))$ | Gaussian 变得不可见 |

所有损失均为负值，越负表示退化越强。log 尺度保证数值稳定。

**陷阱损失总公式**：

$$ \mathcal{L}_{trap} = \sum_{\phi \in \Phi_{active}} \mathcal{L}_\phi $$

其中 $\Phi_{active}$ 是启用的属性集合，由消融实验（Section 5.1）确定最优组合。

#### **Step 2.3: 乘法耦合（Multiplicative Coupling）**

单个陷阱是脆弱的——攻击者可以逐个修复。互锁机制的核心思想是让多个陷阱相互增强，使攻击者无法逐个击破。

将两个 trap loss $\mathcal{L}_1, \mathcal{L}_2$ 通过乘法组合：

$$ \mathcal{L}_{coupled} = -\left((1 - \mathcal{L}_1)(1 - \mathcal{L}_2) - 1\right) $$

**性质：**
- 各 $\mathcal{L}_i < 0$（最小化），所以 $(1 - \mathcal{L}_i) > 1$
- $\mathcal{L}_1$ 的梯度被 $(1 - \mathcal{L}_2)$ 放大，反之亦然
- **效果**：攻击者修复一个 trap 时，另一个 trap 的梯度会更强地抵抗

#### **Step 2.4: 交替反对齐（Alternating Anti-alignment）**

强制两个 trap 在权重空间占据**对抗方向**，使攻击者无法用单一梯度方向同时修复两个 trap。

**机制：**
设两个 trap loss 为 $\mathcal{L}_1, \mathcal{L}_2$，在偶数步以 $\mathcal{L}_1$ 为 active、$\mathcal{L}_2$ 为 reference，奇数步反过来。

对每一层 $l$，计算 active trap 的梯度 $\mathbf{g}_a^l$（可微）和 reference trap 的梯度 $\mathbf{g}_r^l$（detach），直接最小化余弦相似度（推向 -1）：

$$ \mathcal{L}_{conflict} = \lambda_{gc} \cdot \frac{1}{|L|} \sum_{l \in L} \cos\text{sim}(\mathbf{g}_a^l, \mathbf{g}_r^l) $$

#### **Step 2.5: 参数空间噪声鲁棒性（Parameter-Space Noise Robustness）**

攻击者的全参数微调本质上是对模型权重施加一个有方向的扰动 $\Delta\theta$。如果陷阱只在当前权重 $\theta^*$ 处有效，攻击者只需少量梯度步即可逃离陷阱的"有效半径"。为此，我们在训练时显式增强陷阱对权重扰动的鲁棒性。

**机制：**
每 $K$ 步，对模型全参数注入各向同性高斯噪声 $\xi \sim \mathcal{N}(0, \sigma^2 I)$，在扰动后的权重 $\theta + \xi$ 上重新前向传播 target 数据并计算 trap loss：

$$ \mathcal{L}_{robust} = \lambda_{rob} \cdot \left( -\sum_{\phi \in \Phi_{active}} \mathcal{L}_\phi(\theta + \xi) \right) $$

**性质：**
- 最小化 $\mathcal{L}_{robust}$ → 在 $\theta$ 的邻域内 trap loss 仍然强（负值更大）
- 噪声标准差 $\sigma$ 控制鲁棒半径：$\sigma$ 越大，陷阱对更大幅度的权重扰动鲁棒
- 与 adversarial weight perturbation (AWP) 思路类似，但目标相反：AWP 寻找最坏扰动来增强泛化，我们对随机扰动增强陷阱持久性
- 计算开销：每 $K$ 步额外一次前向传播（无需二阶导数）

**与其他组件的协同：**
- 乘法耦合确保多个 trap 互相增强 → 参数加噪确保这种增强在权重邻域内持续
- 交替反对齐确保 trap 梯度方向对抗 → 参数加噪确保这种对抗关系对扰动稳定

### **4. 主实验 (Main Experiment)**

#### 4.1 实验设置

**模型**：LGM-big，在 Objaverse 上预训练。

**数据**：
- Source：Objaverse
- Target：OmniObject3D，测试在4个类别上的结果

**对比方法（3 组）**：

| 方法 | 描述 | 是否需要渲染 |
|------|------|-------------|
| Undefended | 原始 LGM，无任何防御 | - |
| Naive Unlearning | 对 target 数据的渲染 loss（MSE + LPIPS）做梯度上升 + source 蒸馏 | 需要 |
| GeoTrap（完整） | Trap loss + 乘法耦合 + 交替反对齐 + 参数加噪 + source 蒸馏 | 不需要 |

**攻击设置**：全量微调，lr=5e-5，标准渲染 loss（MSE + LPIPS）。

#### 4.2 评估指标

**防御有效性**（攻击后测量，每个类别分别报告）：
- Target LPIPS 随攻击 step 的曲线（越高 = 防御越强）
- Target PSNR 随攻击 step 的曲线（越低 = 防御越强）

**能力保持**（两个时间点）：
- 防御后、攻击前：Source PSNR / LPIPS（衡量防御对 source 的副作用）
- 攻击后：Source PSNR / LPIPS（衡量攻击是否破坏 source 能力）

**定性结果**：渲染对比图（Undefended vs Naive vs GeoTrap，攻击前后，每个类别展示）

---

### **5. 消融实验 (Ablation Studies)**

#### 5.1 Trap 组合消融

系统测试不同几何属性及其组合的防御效果，确定最优 trap 组合。所有实验使用完整互锁机制。

**单属性 trap（4 组）**：

| 属性 | 退化效果 |
|------|---------|
| position | 点云塌缩到平面或直线 |
| scale | Gaussian 退化为纸片或针状 |
| rotation | 所有 Gaussian 朝向趋同 |
| opacity | Gaussian 变得不可见 |

**两两组合（6 组）**：

| 组合 | 退化效果 |
|------|---------|
| position + scale | 位置塌缩 + 尺度退化 |
| position + rotation | 位置塌缩 + 朝向趋同 |
| position + opacity | 位置塌缩 + 透明化 |
| scale + rotation | 尺度退化 + 朝向趋同 |
| scale + opacity | 尺度退化 + 透明化 |
| rotation + opacity | 朝向趋同 + 透明化 |

**验证目标**：
- 哪些几何属性适合作为陷阱（渲染 loss 难以修复）
- 组合优于单 trap（互锁的必要性）
- 确定最优组合

#### 5.2 互锁机制消融

固定最优 trap 组合，逐个去掉互锁组件：

| 实验 | 乘法耦合 | 交替反对齐 | 参数加噪 |
|------|---------|-----------|---------|
| Full GeoTrap | ✓ | ✓ | ✓ |
| w/o 乘法耦合 | ✗（加法） | ✓ | ✓ |
| w/o 交替反对齐 | ✓ | ✗ | ✓ |
| w/o 参数加噪 | ✓ | ✓ | ✗ |
| w/o 所有互锁 | ✗ | ✗ | ✗ |

**验证目标**：每个互锁组件的独立贡献。

#### 5.3 攻击方式泛化

验证防御对不同攻击策略的鲁棒性，涵盖微调方式、优化器、学习率和训练时长：

**微调方式**：

| 攻击方式 | 描述 |
|---------|------|
| 全量微调 | 所有参数可训练（主实验已有） |
| LoRA r=8 | 低秩适配，r=8, alpha=16 |
| LoRA r=16 | 更高秩的 LoRA |

**优化器与学习率**（全量微调下）：

| 优化器 | 学习率 |
|-------|-------|
| AdamW | 5e-5（主实验默认） |
| AdamW | 1e-4, 5e-4 |
| SGD + momentum | 1e-3, 5e-3 |

**攻击时长**（全量微调，AdamW lr=5e-5）：

| 攻击 epoch 数 | 目的 |
|-------------|------|
| 2（默认） | 主实验基准 |
| 5 | 中等攻击预算 |
| 10 | 高攻击预算，测试陷阱持久性 |

**验证目标**：防御不依赖于攻击者的具体微调策略、优化器选择或训练预算。

#### 5.4 防御数据效率

固定每个物体取 3 组视角，测试不同 target 物体数量下的防御效果：

| 每类 target 物体数 | 总 target 样本数 |
|-------------------|-----------------|
| 1 | 3 |
| 3 | 9 |
| 7 | 21 |
| 13 | 39 |

**验证目标**：确定有效防御所需的最少 target 数据量，评估实际部署的可行性。

#### 5.5 防御类别数量扩展

测试同时防御不同数量的 target 类别对防御强度和 source 能力的影响：

| 防御类别数 | 类别 |
|-----------|------|
| 1 | knife |
| 2 | knife + hammer |
| 3 | knife + hammer + scissor |
| 5 | knife + hammer + scissor + fork + razor |

**验证目标**：
- 防御更多类别是否稀释单类别的 trap 强度
- 防御更多类别是否加剧 source 能力退化
- 评估防御的可扩展性（scalability）

---

### **6. 可视化**

所有可视化均为图（无数据表），定量数值已在 Section 4/5 的表格中报告。

#### 6.1 互锁效应与攻击动态（一张图，两个 panel）

在攻击阶段记录每个 attack step 的各 trap loss 值和渲染指标，对比 Full GeoTrap vs 各消融变体（w/o 乘法耦合、w/o 交替反对齐、w/o 所有互锁）。

**左 panel — Trap 轨迹图**：以两个主要 trap loss 为横纵轴（如 $\mathcal{L}_{pos}$ vs $\mathcal{L}_{scale}$），绘制攻击过程中的 2D 轨迹。
- 预期：有互锁时轨迹呈 L 形或锯齿形（攻击者只能修复一个 trap，另一个抵抗），无互锁时轨迹直接走向右上角（两个 trap 同时被修复）。
- 直接体现乘法耦合的联动效应和交替反对齐的方向约束。

**右 panel — 攻击动态曲线**：横轴为 attack step，纵轴为 target LPIPS / target PSNR / 各 trap 指标。
- 预期：Full GeoTrap 的 trap 指标在长时间攻击后仍保持强退化（曲线平坦），消融变体的 trap 指标快速回升。
- 展示陷阱在攻击过程中的持久性。

#### 6.2 参数加噪鲁棒性曲线

防御训练完成后，对模型权重施加不同幅度的各向同性高斯噪声 $\sigma \in \{0, 0.001, 0.005, 0.01, 0.05\}$，在扰动后的权重上前向传播 target 数据，测量 trap loss。

绘制 trap loss vs $\sigma$ 曲线，对比"有加噪训练"vs"无加噪训练"。
- 预期：有加噪训练的曲线衰减平缓（trap 在权重邻域内持续有效），无加噪训练的曲线快速衰减（trap 只在精确权重点有效）。
- 直接验证参数空间噪声鲁棒性机制的有效性。

#### 6.3 定性渲染对比

选取代表性 target 和 source 物体，展示多视角渲染对比图：
- **Target**：原始模型 vs 攻击后（无防御）vs 攻击后（有防御），展示防御对攻击重建质量的破坏
- **Source**：原始模型 vs 防御后（攻击前），展示蒸馏对 source 能力的保持
